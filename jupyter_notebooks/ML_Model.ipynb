{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **This notebook handle ML modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Here we create a ML model to predict diabetes based on the features engineered in the previous notebook.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* The input is the diabeters_model_input.csv file located in the data/transformed directory. This file was generated in the Feature_Engineering notebook. \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# ML model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Import the libraries needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Load the input file to a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Data/transformed/diabetes_model_input.csv')\n",
        "# display the shape and first few rows of the dataframe\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* chekcking for the valule counts of the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['diabetes'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We split the data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate the features and target variable\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['diabetes'],axis=1),\n",
        "                                    df['diabetes'],\n",
        "                                    test_size=0.2,\n",
        "                                   #stratify=df['diabetes'],\n",
        "                                    random_state=42\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* we create a pipeline with a scaler, feature selector and a classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pipeline_logistic_regression():\n",
        "\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            (\"feat_scaling\", StandardScaler()),\n",
        "            (\"feat_selection\", SelectFromModel(LogisticRegression(random_state=42))),\n",
        "            (\"model\", LogisticRegression(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Fit the pipeline with the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = pipeline_logistic_regression()\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next we learn the model coefficients "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def logistic_regression_coef(model, columns):\n",
        "\n",
        "    coeff_df = pd.DataFrame(\n",
        "        model.coef_, index=[\"Coefficient\"], columns=columns\n",
        "    ).T.sort_values([\"Coefficient\"], key=abs, ascending=False)\n",
        "    print(coeff_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logistic_regression_coef(\n",
        "    model=pipeline[\"model\"],\n",
        "    columns=X_train.columns[pipeline[\"feat_selection\"].get_support()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Here's what we observe from the coefficients\n",
        "\n",
        "| Feature              | Coefficient | Interpretation                                                              |\n",
        "|----------------------|-------------|-----------------------------------------------------------------------------|\n",
        "| HbA1c_level          | 2.45        | Strong positive impact on the probability of diabetes                       |\n",
        "| blood_glucose_level  | 1.82        | Also a strong positive impact, but slightly less than HbA1c                 |\n",
        "| age                  | 0.91        | Smaller positive impact, but still relevant                                 |\n",
        "\n",
        "\n",
        "* The model selected the 3 features based on the importance of their logistic regression coefficients.\n",
        "\n",
        "* Among them, HbA1c level is the most influential, followed by blood glucose level, and then age.\n",
        "\n",
        "* The model is interpreting higher values for all three as increasing the chance of the positive outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Now we will look at the confusion matrix and classification report for performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
        "    \n",
        "    prediction = pipeline.predict(X)\n",
        "\n",
        "    print(\"---  Confusion Matrix  ---\")\n",
        "    print(\n",
        "        pd.DataFrame(\n",
        "            confusion_matrix(y_true=y, y_pred=prediction),\n",
        "            columns=[[\"Prediction \" + sub for sub in label_map]],\n",
        "            index=[[\"Actual \" + sub for sub in label_map]],\n",
        "        )\n",
        "    )\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"---  Classification Report  ---\")\n",
        "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
        "    \n",
        "    print(\"#### Train Set #### \\n\")\n",
        "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
        "\n",
        "    print(\"#### Test Set ####\\n\")\n",
        "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_performance(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    pipeline=pipeline,\n",
        "    label_map=[\"No Diabetes\", \"Diabetes\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ What Looks Good\n",
        "\n",
        "- **Overall Accuracy is solid:**\n",
        "  - Train: 85%\n",
        "  - Test: 86%\n",
        "  - No major signs of overfitting or underfitting.\n",
        "\n",
        "- **Performance is slightly better for the 'Diabetes' class**, which is often the more critical one to catch:\n",
        "  - Test set F1-score for Diabetes: 0.87\n",
        "  - Recall for Diabetes: 0.87 (highly valuable in medical diagnosis)\n",
        "\n",
        "- **Balanced macro averages:**  \n",
        "  Precision, recall, and F1 are all around 0.85, which shows that the model doesn't heavily favor one class over another.\n",
        "\n",
        "  ## ‚ö†Ô∏è What Might Be Concerning\n",
        "\n",
        "- **False Negatives (missed diabetes cases):**\n",
        "  - Test: 133 missed diabetic patients\n",
        "  - That's ~13% of diabetic cases going undetected.\n",
        "  - In real-world healthcare, this could be dangerous, as undiagnosed diabetes can lead to complications.\n",
        "\n",
        "- **False Positives (wrongly predicted diabetes):**\n",
        "  - Test: 126 non-diabetic people predicted as diabetic\n",
        "  - This can cause anxiety, unnecessary testing, and cost.\n",
        "  - Even though this number is relatively low, its impact on patient well-being should not be dismissed.\n",
        "\n",
        "  ## ‚öôÔ∏è Experimentation with Stratification and Class Weights\n",
        "\n",
        "I experimented with applying **stratification** and **class-weight balancing** to improve model performance, especially to reduce false negatives.\n",
        "\n",
        "- However, these changes **increased the number of false negatives**, meaning more actual diabetes cases were predicted as no diabetes.\n",
        "- Since **minimizing false negatives is critical** in this healthcare context, I chose **not to keep these changes**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úÖ Summary\n",
        "> The model demonstrates strong and balanced performance, achieving an accuracy of **85% on the training set** and **86% on the test set**. It maintains consistent precision and recall across both classes, with particularly good performance in identifying diabetes cases (**F1-score: 0.87** on the test set). The confusion matrix reveals a manageable number of false negatives and false positives, but since this is a healthcare application, further steps may be needed to validate these predictions before clinical action is taken."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Implementing a Random Forest Classifier to see if it improves performance over Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Define the pipeline with a scaler, feature selector and the Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pipeline_rf_clf():\n",
        "  pipeline = Pipeline([\n",
        "      ( \"feat_scaling\",StandardScaler() ),\n",
        "      ( \"feat_selection\",SelectFromModel(RandomForestClassifier(random_state=42)) ),\n",
        "      ( \"model\", RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)),\n",
        "\n",
        "    ])\n",
        "\n",
        "  return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Using GridSearchCV to find the best hyperparameters for the Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# param_grid = {\"model__n_estimators\":[50,20],\n",
        "#               }\n",
        "\n",
        "# param_grid = {\n",
        "#     'model__n_estimators': [50, 100],\n",
        "#     'model__max_depth': [None, 10, 20]\n",
        "# }\n",
        "\n",
        "# param_grid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# grid = GridSearchCV(estimator=pipeline_rf_clf(),\n",
        "#                     param_grid=param_grid,\n",
        "#                     cv=2,\n",
        "#                     n_jobs=-2,\n",
        "#                     verbose=1,\n",
        "#                     scoring=make_scorer(recall_score, pos_label=1)\n",
        "#                     )\n",
        "\n",
        "# grid = GridSearchCV(\n",
        "#     estimator=pipeline_rf_clf(),\n",
        "#     param_grid=param_grid,\n",
        "#     scoring=make_scorer(recall_score, pos_label=1),  # assuming 1 = 'Diabetes'\n",
        "#     cv=3,\n",
        "#     n_jobs=-1,\n",
        "#     verbose=2\n",
        "# )\n",
        "\n",
        "# grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* we check the resulst of 4 models using cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (pd.DataFrame(grid.cv_results_)\n",
        "# .sort_values(by='mean_test_score',ascending=False)\n",
        "# .filter(['params','mean_test_score'])\n",
        "# .values\n",
        "#  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* checking the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# grid.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* getting the pipeline with the best estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_rf = pipeline_rf_clf()\n",
        "pipeline_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* evaluate the model with a confusion matrix and classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=pipeline_rf,\n",
        "                label_map= ['No Diabetes', 'Diabetes'] \n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Side-by-Side Comparison\n",
        "\n",
        "#### ‚úÖ Accuracy\n",
        "\n",
        "| Model              | Train Accuracy | Test Accuracy |\n",
        "|--------------------|----------------|---------------|\n",
        "| Random Forest      | 91%            | 90%           |\n",
        "| Logistic Regression | 85%            | 86%           |\n",
        "\n",
        "> üîπ **Winner: Random Forest** ‚Äî better overall accuracy, and smaller train-test gap.\n",
        "\n",
        "---\n",
        "\n",
        "#### ‚úÖ Recall (especially important for Diabetes class)\n",
        "\n",
        "| Model              | Train Recall ‚Äì Diabetes | Test Recall ‚Äì Diabetes |\n",
        "|--------------------|------------------------|-----------------------|\n",
        "| Random Forest      | 0.94                   | 0.94                  |\n",
        "| Logistic Regression | 0.86                   | 0.87                  |\n",
        "\n",
        "> üîπ **Winner: Random Forest** ‚Äî significantly higher recall for the Diabetes class, which is crucial in medical diagnosis.\n",
        "\n",
        "---\n",
        "\n",
        "#### ‚úÖ False Negatives (missed diabetes cases)\n",
        "\n",
        "| Model              | Test False Negatives    |\n",
        "|--------------------|------------------------|\n",
        "| Random Forest      | 66 (6.5%)               |\n",
        "| Logistic Regression | 133 (13%)               |\n",
        "\n",
        "> üîπ **Winner: Random Forest** ‚Äî detects more true diabetes cases (almost halves the number of missed diagnoses).\n",
        "\n",
        "### ‚úÖ Final Verdict\n",
        "\n",
        "Random Forest clearly outperforms Logistic Regression across all major metrics, especially in terms of recall for diabetic patients, overall accuracy, and reduction in false negatives ‚Äî making it the stronger choice between the 2 models for this diabetes prediction task.\n",
        "\n",
        "## ‚öôÔ∏è Experimentation with hyperparameter optimisation\n",
        "\n",
        "- Initially tried with just 'n_estimators' but the model overfitted the training data. The recall rate in train set was 1 but it was performing poorly on the test set. \n",
        "\n",
        "- So added 'max_depth' to the hyperparameter grid to control the depth of each tree in the forest.\n",
        "\n",
        "- This helped reduce overfitting and improved generalization to unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
